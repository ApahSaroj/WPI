{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoML-FLAML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPGFTF7+oCW4ZdrffuobXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApahSaroj/WPI/blob/main/AutoML_FLAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSaGF3gd0n3m"
      },
      "source": [
        "https://github.com/microsoft/FLAML/blob/main/notebook/flaml_xgboost.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiMaAgzDwLz_",
        "outputId": "3522f69d-b84c-42fe-8203-f2bc5f8adbc0"
      },
      "source": [
        "pip install flaml[notebook];"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flaml[notebook] in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.24.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.90)\n",
            "Requirement already satisfied: catboost>=0.23 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.26)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.2.1)\n",
            "Requirement already satisfied: openml==0.10.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.10.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.0.0)\n",
            "Requirement already satisfied: matplotlib==3.2.0 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.2.0)\n",
            "Requirement already satisfied: rgf-python in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.10.0)\n",
            "Requirement already satisfied: vowpalwabbit in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (8.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (2.4.7)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (0.12.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (1.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[notebook]) (0.36.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->openml==0.10.2->flaml[notebook]) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->flaml[notebook]) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->flaml[notebook]) (2.2.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (7.6.3)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.0.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.3.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (57.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter->flaml[notebook]) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (3.5.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (2.6.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (1.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (0.10.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->flaml[notebook]) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->flaml[notebook]) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->flaml[notebook]) (2.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (3.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (21.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.23->flaml[notebook]) (1.3.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->flaml[notebook]) (1.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LMEP4wB6DLM"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yNBe7EG7a0t",
        "outputId": "45977b40-f123-4ffd-df01-5ed8e6355d97"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6uU8XO897dcF",
        "outputId": "bb43d487-5efd-4bf5-fa17-628c265f80f8"
      },
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/DATA/WQC_test.xlsx')\n",
        "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "df.drop(df.columns[df.columns.str.contains('WQC',case = False)],axis = 1, inplace = True)\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>DO</th>\n",
              "      <th>TDS</th>\n",
              "      <th>Alkalinity</th>\n",
              "      <th>EC</th>\n",
              "      <th>Na</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Mg</th>\n",
              "      <th>K</th>\n",
              "      <th>F</th>\n",
              "      <th>Cl</th>\n",
              "      <th>Nitrate</th>\n",
              "      <th>Sulphate</th>\n",
              "      <th>Phosphate</th>\n",
              "      <th>WPI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.14</td>\n",
              "      <td>8.7</td>\n",
              "      <td>84.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>147.8</td>\n",
              "      <td>4.48</td>\n",
              "      <td>44.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.285</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.758000</td>\n",
              "      <td>6.534660</td>\n",
              "      <td>0.06211</td>\n",
              "      <td>0.249528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.70</td>\n",
              "      <td>8.8</td>\n",
              "      <td>110.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>8.61</td>\n",
              "      <td>44.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>3.46</td>\n",
              "      <td>0.401</td>\n",
              "      <td>14.80</td>\n",
              "      <td>0.196062</td>\n",
              "      <td>8.138620</td>\n",
              "      <td>0.00960</td>\n",
              "      <td>0.216400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.60</td>\n",
              "      <td>7.5</td>\n",
              "      <td>75.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.11</td>\n",
              "      <td>28.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0.379</td>\n",
              "      <td>14.80</td>\n",
              "      <td>0.298875</td>\n",
              "      <td>3.855625</td>\n",
              "      <td>0.01280</td>\n",
              "      <td>0.183814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.20</td>\n",
              "      <td>9.1</td>\n",
              "      <td>76.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>44.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.396</td>\n",
              "      <td>9.60</td>\n",
              "      <td>0.299590</td>\n",
              "      <td>2.238750</td>\n",
              "      <td>0.01536</td>\n",
              "      <td>0.219282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.31</td>\n",
              "      <td>7.3</td>\n",
              "      <td>84.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>5.50</td>\n",
              "      <td>28.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.61</td>\n",
              "      <td>0.265</td>\n",
              "      <td>8.30</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>0.165831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>7.60</td>\n",
              "      <td>5.6</td>\n",
              "      <td>224.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>16.14</td>\n",
              "      <td>92.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7.60</td>\n",
              "      <td>2.270</td>\n",
              "      <td>23.04</td>\n",
              "      <td>1.352000</td>\n",
              "      <td>104.480000</td>\n",
              "      <td>0.01500</td>\n",
              "      <td>0.419630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>7.30</td>\n",
              "      <td>5.6</td>\n",
              "      <td>266.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>20.56</td>\n",
              "      <td>96.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>9.89</td>\n",
              "      <td>1.550</td>\n",
              "      <td>30.86</td>\n",
              "      <td>7.074000</td>\n",
              "      <td>61.068000</td>\n",
              "      <td>0.03300</td>\n",
              "      <td>0.432996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>5.10</td>\n",
              "      <td>5.8</td>\n",
              "      <td>290.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>487.0</td>\n",
              "      <td>37.35</td>\n",
              "      <td>60.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>0.159</td>\n",
              "      <td>60.13</td>\n",
              "      <td>9.256000</td>\n",
              "      <td>89.910000</td>\n",
              "      <td>0.16300</td>\n",
              "      <td>0.326811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>7.40</td>\n",
              "      <td>6.4</td>\n",
              "      <td>230.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>20.06</td>\n",
              "      <td>70.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>10.35</td>\n",
              "      <td>1.360</td>\n",
              "      <td>32.92</td>\n",
              "      <td>7.110435</td>\n",
              "      <td>48.500000</td>\n",
              "      <td>0.21900</td>\n",
              "      <td>0.509970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>7.60</td>\n",
              "      <td>6.9</td>\n",
              "      <td>243.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>410.8</td>\n",
              "      <td>17.41</td>\n",
              "      <td>82.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.92</td>\n",
              "      <td>1.310</td>\n",
              "      <td>34.89</td>\n",
              "      <td>6.385000</td>\n",
              "      <td>59.940000</td>\n",
              "      <td>0.07000</td>\n",
              "      <td>0.422551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>487 rows Ã— 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pH   DO    TDS  Alkalinity  ...   Nitrate    Sulphate  Phosphate       WPI\n",
              "0    8.14  8.7   84.0        52.0  ...  0.758000    6.534660    0.06211  0.249528\n",
              "1    7.70  8.8  110.0        76.0  ...  0.196062    8.138620    0.00960  0.216400\n",
              "2    7.60  7.5   75.0        44.0  ...  0.298875    3.855625    0.01280  0.183814\n",
              "3    8.20  9.1   76.0        56.0  ...  0.299590    2.238750    0.01536  0.219282\n",
              "4    7.31  7.3   84.0        52.0  ...  0.106000    5.600000    0.01000  0.165831\n",
              "..    ...  ...    ...         ...  ...       ...         ...        ...       ...\n",
              "482  7.60  5.6  224.0         8.0  ...  1.352000  104.480000    0.01500  0.419630\n",
              "483  7.30  5.6  266.0        96.0  ...  7.074000   61.068000    0.03300  0.432996\n",
              "484  5.10  5.8  290.0        12.0  ...  9.256000   89.910000    0.16300  0.326811\n",
              "485  7.40  6.4  230.0        72.0  ...  7.110435   48.500000    0.21900  0.509970\n",
              "486  7.60  6.9  243.0        68.0  ...  6.385000   59.940000    0.07000  0.422551\n",
              "\n",
              "[487 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xd2OEpaCphH",
        "outputId": "cb3757ac-4952-48a8-c4e0-81c6f341bea3"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pH            0\n",
            "DO            0\n",
            "TDS           0\n",
            "Alkalinity    0\n",
            "EC            0\n",
            "Na            0\n",
            "Ca            0\n",
            "Mg            0\n",
            "K             0\n",
            "F             0\n",
            "Cl            0\n",
            "Nitrate       0\n",
            "Sulphate      0\n",
            "Phosphate     2\n",
            "WPI           0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxwMwAmVDJGM"
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0UgsxXJ-q4k",
        "outputId": "aba784c6-759a-43fd-c019-455ba13ad1fb"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pH            0\n",
            "DO            0\n",
            "TDS           0\n",
            "Alkalinity    0\n",
            "EC            0\n",
            "Na            0\n",
            "Ca            0\n",
            "Mg            0\n",
            "K             0\n",
            "F             0\n",
            "Cl            0\n",
            "Nitrate       0\n",
            "Sulphate      0\n",
            "Phosphate     0\n",
            "WPI           0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ4K4QORwGjT",
        "outputId": "60697c05-9f59-4bfe-a9aa-f32598b5cc40"
      },
      "source": [
        "# Taking  all rows and all columns in the data except the last column as X (feature matrix)\n",
        "#the row numbers and customer id's are not necessary for the modelling so we get rid of and start with credit score\n",
        "X = df.iloc[:,0:-1].values\n",
        "print(\"Independent variables are:\", X)\n",
        "#taking all rows but only the last column as Y(dependent variable)\n",
        "y = df.iloc[:, -1].values\n",
        "print(\"Dependent variable is:\", y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Independent variables are: [[8.1400000e+00 8.7000000e+00 8.4000000e+01 ... 7.5800000e-01\n",
            "  6.5346600e+00 6.2110500e-02]\n",
            " [7.7000000e+00 8.8000000e+00 1.1000000e+02 ... 1.9606200e-01\n",
            "  8.1386200e+00 9.6000000e-03]\n",
            " [7.6000000e+00 7.5000000e+00 7.5000000e+01 ... 2.9887500e-01\n",
            "  3.8556250e+00 1.2800000e-02]\n",
            " ...\n",
            " [5.1000000e+00 5.8000000e+00 2.9000000e+02 ... 9.2560000e+00\n",
            "  8.9910000e+01 1.6300000e-01]\n",
            " [7.4000000e+00 6.4000000e+00 2.3000000e+02 ... 7.1104355e+00\n",
            "  4.8500000e+01 2.1900000e-01]\n",
            " [7.6000000e+00 6.9000000e+00 2.4300000e+02 ... 6.3850000e+00\n",
            "  5.9940000e+01 7.0000000e-02]]\n",
            "Dependent variable is: [0.24952772 0.21639962 0.18381411 0.21928185 0.16583135 0.30862698\n",
            " 0.4068906  0.29180421 0.21992977 0.23733965 0.26441304 0.27733543\n",
            " 0.2477512  0.25743115 0.51679302 0.21917643 0.26586048 0.26586048\n",
            " 0.25265698 0.28963056 0.38051071 0.36357127 0.28449556 0.25478242\n",
            " 0.25471889 0.37001056 0.2216364  0.2780727  0.25375634 0.23331203\n",
            " 0.20389072 0.28741993 0.18819563 0.29640025 0.27678567 0.29634413\n",
            " 0.2979126  0.23889379 0.23232578 0.20737447 0.23126844 0.21646111\n",
            " 0.54095524 0.19022492 0.19187885 0.19187885 0.28793111 0.27000008\n",
            " 0.19715456 0.19927266 0.22087373 0.24873206 0.25393246 0.21712558\n",
            " 0.23952114 0.34336337 0.39979483 0.46795082 0.43402287 0.32359447\n",
            " 0.2522879  0.26604911 0.27473237 0.32928729 0.3346854  0.39913466\n",
            " 0.4092163  0.25682131 0.40748944 0.39741013 0.43672625 0.42367496\n",
            " 0.50541175 0.24844207 0.32023133 0.24183576 0.45020199 0.29696464\n",
            " 0.36944037 0.37611243 0.40909747 0.42209217 0.90932513 0.41050516\n",
            " 0.46988341 0.29144097 0.30586849 0.25873847 0.25962175 0.23031838\n",
            " 0.23778331 0.32253242 0.28982333 0.22432571 0.24680849 0.31265151\n",
            " 0.31265151 0.24358782 0.25477349 0.23562853 0.42178722 0.40891659\n",
            " 0.38074108 0.30854357 0.70995359 0.34229376 0.3777435  0.29783829\n",
            " 0.35554789 0.74494365 0.36259615 0.25411581 0.17794698 0.21352858\n",
            " 0.196794   0.35642371 0.24635819 0.34143187 0.39445262 0.25267146\n",
            " 0.25049126 0.43302522 0.29166937 0.78753263 0.50551297 0.27043127\n",
            " 0.21657617 0.26618408 0.34177695 0.27698476 0.38239762 0.31614178\n",
            " 0.33307531 0.45375315 0.29133539 0.35954841 0.24632016 0.26486387\n",
            " 0.22513802 0.32960003 0.30256905 0.50211921 0.40511291 1.60437451\n",
            " 0.28369611 0.28411643 0.27637746 0.21748365 0.21748365 0.27369738\n",
            " 0.28838825 0.29675401 0.34431841 0.40171385 0.30601855 0.2373423\n",
            " 0.39880492 0.37855777 0.28932958 0.19901267 0.24579721 0.37357881\n",
            " 0.1947727  0.23413803 0.18936165 0.19050383 0.25658199 0.2352364\n",
            " 0.15288492 0.18138333 0.17251986 0.21594667 0.21662506 0.24510856\n",
            " 0.18853009 0.23798032 0.23292773 0.54591043 0.18107322 0.17969446\n",
            " 0.10353119 0.24226057 0.49942293 0.20623071 0.2863976  0.20083842\n",
            " 0.20879087 0.21661437 0.253804   0.28302444 0.19510906 0.17856737\n",
            " 0.17522634 0.20525832 0.86533941 0.5043202  0.35319151 0.24254286\n",
            " 0.76730889 0.76730889 0.19798929 0.18294044 0.68976056 0.16264214\n",
            " 0.31588048 0.16853484 0.23964944 0.70540516 0.24831747 0.3815332\n",
            " 0.18750125 0.35770275 0.24345317 0.25335627 0.23491415 0.24130071\n",
            " 0.22343726 0.23102641 0.25325176 0.20335359 0.23822883 0.18890324\n",
            " 0.30361883 0.25541869 0.22447942 0.25595005 0.24174468 0.22770833\n",
            " 0.23283827 0.21516789 0.22514142 0.26355576 0.21016208 0.23009967\n",
            " 0.18683124 0.28519791 0.17749364 0.20850588 0.26945119 0.2975256\n",
            " 0.21406141 0.2023169  0.18643048 0.26871048 0.18377062 0.20865208\n",
            " 0.94368132 0.23549833 0.22917242 0.25532952 0.20279881 0.20279881\n",
            " 0.22852274 0.37093802 0.22319746 0.18669778 0.26244317 0.362986\n",
            " 0.22040246 0.24627079 0.22385105 0.21137434 0.23043176 0.26470756\n",
            " 0.22725153 0.44999242 0.24739031 0.27796838 0.23139673 0.21913512\n",
            " 0.28328389 0.17191065 0.25135283 0.20552839 0.34352046 0.2616692\n",
            " 0.21065268 0.21277645 0.23953789 0.24829809 0.25892407 0.25408484\n",
            " 0.23176095 0.27137222 0.27525951 0.20747128 0.21694915 0.24041668\n",
            " 0.16528437 0.25296851 0.22668651 0.32497408 0.26758524 0.18092857\n",
            " 0.21798742 0.23220198 0.19546092 0.20626019 0.25086902 0.27335627\n",
            " 0.24031944 0.24391635 0.22345341 0.22345341 0.29843492 0.43151825\n",
            " 0.29622988 0.21012147 0.2815921  0.33606539 0.31115992 0.28409183\n",
            " 0.25679179 0.32077402 0.41682313 0.22201358 0.27818809 0.25100178\n",
            " 0.20825377 0.32024448 0.21773848 0.20437718 0.21300363 0.20263432\n",
            " 0.25238366 0.20629842 0.21617291 0.20029738 0.46018895 0.25633904\n",
            " 0.21771809 0.23083957 0.23824151 0.1601987  0.20353225 0.24204777\n",
            " 0.2042493  0.20786689 0.2378321  0.21068138 0.20353016 0.29083595\n",
            " 0.23400789 0.25925357 0.16286362 0.22826206 0.23031838 0.23778331\n",
            " 0.32253242 0.28982333 0.22432571 0.24680849 0.31265151 0.31265151\n",
            " 0.24358782 0.25477349 0.23562853 0.22153071 0.24608365 0.31237174\n",
            " 0.20765063 0.24834024 0.25136601 0.2141382  0.28755821 0.22630523\n",
            " 0.3526167  0.26400176 0.25053893 0.23822668 0.21710491 0.2716523\n",
            " 0.22515148 0.27075974 0.25113395 0.2131049  0.2458685  0.27102795\n",
            " 0.2856845  0.34809697 0.27969963 0.2638786  0.19548552 0.24754832\n",
            " 0.3473529  0.21591782 0.24800347 0.2472355  0.24491613 0.25188896\n",
            " 0.28452091 0.33224359 0.27245635 0.31846135 0.27729925 0.2585854\n",
            " 0.22526094 0.24832671 0.26197317 0.1819046  0.30347514 0.27991488\n",
            " 0.22384409 0.24836833 0.49455802 0.49455802 0.25063885 0.29666794\n",
            " 0.24059611 1.01539504 0.32699198 0.89107969 0.51817325 0.33987286\n",
            " 0.28036891 0.30566035 0.18683124 0.28519791 0.17749364 0.20850588\n",
            " 0.26945119 0.2975256  0.21406141 0.2023169  0.18643048 0.26871048\n",
            " 0.41627308 0.54312336 0.48665542 0.38356984 0.57180254 0.42344362\n",
            " 0.52739425 0.44275837 0.47973984 0.24952772 0.21639962 0.18381411\n",
            " 0.21928185 0.16583135 0.30862698 0.4068906  0.29180421 0.21992977\n",
            " 0.23733965 0.26214353 0.29819355 0.26196344 0.57650019 0.20174444\n",
            " 0.24306786 0.4242409  0.31035341 0.25795989 0.27636587 0.25565265\n",
            " 0.2493593  0.2368416  0.29905025 0.22571429 0.30334256 0.29721459\n",
            " 0.21345381 0.19119542 0.28623486 0.25490388 0.22369318 0.36601494\n",
            " 0.30672798 0.31489782 0.22000429 0.21882067 0.24272635 0.22283376\n",
            " 0.21248944 0.47651193 0.48136427 0.50820582 0.38128842 0.44859762\n",
            " 0.41963032 0.4329961  0.32681063 0.5099695  0.42255063]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm6AMoQGw-hH",
        "outputId": "0412e9f5-7f5b-4d19-fcca-b0e6453d8800"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "#printing the dimensions of each of those snapshots to see amount of rows and columns i each of them\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(388, 14) (97, 14)\n",
            "(388,) (97,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXV3BCxBwhT4"
      },
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdifihGq0kbj"
      },
      "source": [
        "settings = {\n",
        "    \"time_budget\": 60,  # total running time in seconds\n",
        "    \"metric\": 'r2',  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
        "    \"estimator_list\": ['xgboost'],  # list of ML learners; we tune xgboost in this example\n",
        "    \"task\": 'regression',  # task type    \n",
        "    \"log_file_name\": 'houses_experiment.log',  # flaml log file\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wobjmRne1-8D",
        "outputId": "c95d37f5-1b04-4624-ea84-b522afe1c5df"
      },
      "source": [
        "automl.fit(X_train=X_train, y_train=y_train, **settings)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[flaml.automl: 08-01 03:53:08] {913} INFO - Evaluation method: cv\n",
            "[flaml.automl: 08-01 03:53:08] {617} INFO - Using RepeatedKFold\n",
            "[flaml.automl: 08-01 03:53:08] {934} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 08-01 03:53:08] {954} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
            "[flaml.automl: 08-01 03:53:08] {1020} INFO - iteration 0, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.1s,\tbest xgboost's error=2.1787,\tbest xgboost's error=2.1787\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 1, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.1s,\tbest xgboost's error=2.1787,\tbest xgboost's error=2.1787\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 2, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.2s,\tbest xgboost's error=0.7034,\tbest xgboost's error=0.7034\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.2s,\tbest xgboost's error=0.3599,\tbest xgboost's error=0.3599\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.3s,\tbest xgboost's error=0.3599,\tbest xgboost's error=0.3599\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.3s,\tbest xgboost's error=0.2657,\tbest xgboost's error=0.2657\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.3s,\tbest xgboost's error=0.2657,\tbest xgboost's error=0.2657\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 7, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 8, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 0.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 1.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 1.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:09] {1180} INFO -  at 1.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:09] {1020} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.2s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.2s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.2s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.3s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 31, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.3s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 1.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 2.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:10] {1180} INFO -  at 2.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:10] {1020} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 52, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 53, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.2s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.2s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.3s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.3s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 2.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 3.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:11] {1180} INFO -  at 3.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:11] {1020} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 76, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.1s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.2s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 79, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.2s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.3s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.3s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.3s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.4s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.5s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.6s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 92, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.7s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 94, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.8s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 3.9s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 4.0s,\tbest xgboost's error=0.1699,\tbest xgboost's error=0.1699\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:12] {1180} INFO -  at 4.0s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:12] {1020} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.1s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.1s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 102, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.2s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.2s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.3s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.3s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.4s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.4s,\tbest xgboost's error=0.1434,\tbest xgboost's error=0.1434\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.5s,\tbest xgboost's error=0.1409,\tbest xgboost's error=0.1409\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 109, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.6s,\tbest xgboost's error=0.1409,\tbest xgboost's error=0.1409\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 110, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.7s,\tbest xgboost's error=0.1409,\tbest xgboost's error=0.1409\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 111, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.7s,\tbest xgboost's error=0.1409,\tbest xgboost's error=0.1409\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 112, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.8s,\tbest xgboost's error=0.1409,\tbest xgboost's error=0.1409\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 113, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 4.9s,\tbest xgboost's error=0.1135,\tbest xgboost's error=0.1135\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 114, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:13] {1180} INFO -  at 5.0s,\tbest xgboost's error=0.1135,\tbest xgboost's error=0.1135\n",
            "[flaml.automl: 08-01 03:53:13] {1020} INFO - iteration 115, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:14] {1180} INFO -  at 5.1s,\tbest xgboost's error=0.1135,\tbest xgboost's error=0.1135\n",
            "[flaml.automl: 08-01 03:53:14] {1020} INFO - iteration 116, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:14] {1180} INFO -  at 5.3s,\tbest xgboost's error=0.1135,\tbest xgboost's error=0.1135\n",
            "[flaml.automl: 08-01 03:53:14] {1020} INFO - iteration 117, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:14] {1180} INFO -  at 5.4s,\tbest xgboost's error=0.1135,\tbest xgboost's error=0.1135\n",
            "[flaml.automl: 08-01 03:53:14] {1020} INFO - iteration 118, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:14] {1180} INFO -  at 5.4s,\tbest xgboost's error=0.1135,\tbest xgboost's error=0.1135\n",
            "[flaml.automl: 08-01 03:53:14] {1020} INFO - iteration 119, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:14] {1180} INFO -  at 5.5s,\tbest xgboost's error=0.1135,\tbest xgboost's error=0.1135\n",
            "[flaml.automl: 08-01 03:53:14] {1020} INFO - iteration 120, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:14] {1180} INFO -  at 5.7s,\tbest xgboost's error=0.1101,\tbest xgboost's error=0.1101\n",
            "[flaml.automl: 08-01 03:53:14] {1020} INFO - iteration 121, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:14] {1180} INFO -  at 5.9s,\tbest xgboost's error=0.1101,\tbest xgboost's error=0.1101\n",
            "[flaml.automl: 08-01 03:53:14] {1020} INFO - iteration 122, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:15] {1180} INFO -  at 6.2s,\tbest xgboost's error=0.1101,\tbest xgboost's error=0.1101\n",
            "[flaml.automl: 08-01 03:53:15] {1020} INFO - iteration 123, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:15] {1180} INFO -  at 6.4s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:15] {1020} INFO - iteration 124, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:15] {1180} INFO -  at 6.6s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:15] {1020} INFO - iteration 125, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:15] {1180} INFO -  at 6.7s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:15] {1020} INFO - iteration 126, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:16] {1180} INFO -  at 7.1s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:16] {1020} INFO - iteration 127, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:16] {1180} INFO -  at 7.2s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:16] {1020} INFO - iteration 128, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:16] {1180} INFO -  at 7.6s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:16] {1020} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:16] {1180} INFO -  at 7.7s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:16] {1020} INFO - iteration 130, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:17] {1180} INFO -  at 8.2s,\tbest xgboost's error=0.1087,\tbest xgboost's error=0.1087\n",
            "[flaml.automl: 08-01 03:53:17] {1020} INFO - iteration 131, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:17] {1180} INFO -  at 8.4s,\tbest xgboost's error=0.1061,\tbest xgboost's error=0.1061\n",
            "[flaml.automl: 08-01 03:53:17] {1020} INFO - iteration 132, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:17] {1180} INFO -  at 8.7s,\tbest xgboost's error=0.1061,\tbest xgboost's error=0.1061\n",
            "[flaml.automl: 08-01 03:53:17] {1020} INFO - iteration 133, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:17] {1180} INFO -  at 8.8s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:17] {1020} INFO - iteration 134, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:17] {1180} INFO -  at 9.0s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:17] {1020} INFO - iteration 135, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:18] {1180} INFO -  at 9.1s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:18] {1020} INFO - iteration 136, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:18] {1180} INFO -  at 9.4s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:18] {1020} INFO - iteration 137, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:18] {1180} INFO -  at 9.5s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:18] {1020} INFO - iteration 138, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:18] {1180} INFO -  at 9.7s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:18] {1020} INFO - iteration 139, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:18] {1180} INFO -  at 9.8s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:18] {1020} INFO - iteration 140, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:18] {1180} INFO -  at 10.0s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:18] {1020} INFO - iteration 141, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:19] {1180} INFO -  at 10.2s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:19] {1020} INFO - iteration 142, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:19] {1180} INFO -  at 10.3s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:19] {1020} INFO - iteration 143, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:19] {1180} INFO -  at 10.5s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:19] {1020} INFO - iteration 144, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:19] {1180} INFO -  at 10.7s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:19] {1020} INFO - iteration 145, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:19] {1180} INFO -  at 10.8s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:19] {1020} INFO - iteration 146, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:19] {1180} INFO -  at 11.0s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:19] {1020} INFO - iteration 147, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:20] {1180} INFO -  at 11.2s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:20] {1020} INFO - iteration 148, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:20] {1180} INFO -  at 11.3s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:20] {1020} INFO - iteration 149, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:20] {1180} INFO -  at 11.5s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:20] {1020} INFO - iteration 150, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:20] {1180} INFO -  at 11.6s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:20] {1020} INFO - iteration 151, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:20] {1180} INFO -  at 11.8s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:20] {1020} INFO - iteration 152, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:20] {1180} INFO -  at 11.9s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:20] {1020} INFO - iteration 153, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:20] {1180} INFO -  at 12.0s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:20] {1020} INFO - iteration 154, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:21] {1180} INFO -  at 12.2s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:21] {1020} INFO - iteration 155, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:21] {1180} INFO -  at 12.3s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:21] {1020} INFO - iteration 156, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:21] {1180} INFO -  at 12.6s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:21] {1020} INFO - iteration 157, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:21] {1180} INFO -  at 12.7s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:21] {1020} INFO - iteration 158, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:21] {1180} INFO -  at 12.9s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:21] {1020} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:22] {1180} INFO -  at 13.2s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:22] {1020} INFO - iteration 160, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:22] {1180} INFO -  at 13.2s,\tbest xgboost's error=0.1027,\tbest xgboost's error=0.1027\n",
            "[flaml.automl: 08-01 03:53:22] {1020} INFO - iteration 161, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:22] {1180} INFO -  at 13.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:22] {1020} INFO - iteration 162, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:22] {1180} INFO -  at 13.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:22] {1020} INFO - iteration 163, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:22] {1180} INFO -  at 13.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:22] {1020} INFO - iteration 164, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:22] {1180} INFO -  at 14.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:22] {1020} INFO - iteration 165, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:23] {1180} INFO -  at 14.3s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:23] {1020} INFO - iteration 166, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:23] {1180} INFO -  at 14.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:23] {1020} INFO - iteration 167, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:23] {1180} INFO -  at 14.5s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:23] {1020} INFO - iteration 168, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:23] {1180} INFO -  at 14.7s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:23] {1020} INFO - iteration 169, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:23] {1180} INFO -  at 14.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:23] {1020} INFO - iteration 170, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:24] {1180} INFO -  at 15.2s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:24] {1020} INFO - iteration 171, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:24] {1180} INFO -  at 15.3s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:24] {1020} INFO - iteration 172, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:24] {1180} INFO -  at 15.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:24] {1020} INFO - iteration 173, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:24] {1180} INFO -  at 15.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:24] {1020} INFO - iteration 174, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:24] {1180} INFO -  at 16.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:24] {1020} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:25] {1180} INFO -  at 16.3s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:25] {1020} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:25] {1180} INFO -  at 16.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:25] {1020} INFO - iteration 177, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:25] {1180} INFO -  at 16.7s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:25] {1020} INFO - iteration 178, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:25] {1180} INFO -  at 16.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:25] {1020} INFO - iteration 179, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:25] {1180} INFO -  at 17.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:25] {1020} INFO - iteration 180, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:26] {1180} INFO -  at 17.2s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:26] {1020} INFO - iteration 181, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:26] {1180} INFO -  at 17.5s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:26] {1020} INFO - iteration 182, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:26] {1180} INFO -  at 17.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:26] {1020} INFO - iteration 183, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:26] {1180} INFO -  at 17.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:26] {1020} INFO - iteration 184, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:26] {1180} INFO -  at 18.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:26] {1020} INFO - iteration 185, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:26] {1180} INFO -  at 18.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:26] {1020} INFO - iteration 186, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:27] {1180} INFO -  at 18.5s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:27] {1020} INFO - iteration 187, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:27] {1180} INFO -  at 18.7s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:27] {1020} INFO - iteration 188, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:27] {1180} INFO -  at 18.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:27] {1020} INFO - iteration 189, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:28] {1180} INFO -  at 19.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:28] {1020} INFO - iteration 190, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:28] {1180} INFO -  at 19.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:28] {1020} INFO - iteration 191, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:28] {1180} INFO -  at 19.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:28] {1020} INFO - iteration 192, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:28] {1180} INFO -  at 19.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:28] {1020} INFO - iteration 193, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:28] {1180} INFO -  at 19.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:28] {1020} INFO - iteration 194, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:29] {1180} INFO -  at 20.2s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:29] {1020} INFO - iteration 195, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:29] {1180} INFO -  at 20.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:29] {1020} INFO - iteration 196, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:29] {1180} INFO -  at 20.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:29] {1020} INFO - iteration 197, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:29] {1180} INFO -  at 20.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:29] {1020} INFO - iteration 198, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:29] {1180} INFO -  at 20.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:29] {1020} INFO - iteration 199, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:30] {1180} INFO -  at 21.1s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:30] {1020} INFO - iteration 200, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:30] {1180} INFO -  at 21.3s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:30] {1020} INFO - iteration 201, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:30] {1180} INFO -  at 21.7s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:30] {1020} INFO - iteration 202, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:30] {1180} INFO -  at 21.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:30] {1020} INFO - iteration 203, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:30] {1180} INFO -  at 21.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:30] {1020} INFO - iteration 204, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:31] {1180} INFO -  at 22.2s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:31] {1020} INFO - iteration 205, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:31] {1180} INFO -  at 22.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:31] {1020} INFO - iteration 206, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:31] {1180} INFO -  at 22.5s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:31] {1020} INFO - iteration 207, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:31] {1180} INFO -  at 22.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:31] {1020} INFO - iteration 208, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:31] {1180} INFO -  at 22.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:31] {1020} INFO - iteration 209, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:32] {1180} INFO -  at 23.1s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:32] {1020} INFO - iteration 210, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:32] {1180} INFO -  at 23.2s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:32] {1020} INFO - iteration 211, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:32] {1180} INFO -  at 23.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:32] {1020} INFO - iteration 212, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:32] {1180} INFO -  at 23.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:32] {1020} INFO - iteration 213, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:32] {1180} INFO -  at 23.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:32] {1020} INFO - iteration 214, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:33] {1180} INFO -  at 24.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:33] {1020} INFO - iteration 215, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:33] {1180} INFO -  at 24.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:33] {1020} INFO - iteration 216, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:33] {1180} INFO -  at 24.5s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:33] {1020} INFO - iteration 217, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:33] {1180} INFO -  at 24.7s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:33] {1020} INFO - iteration 218, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:33] {1180} INFO -  at 24.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:33] {1020} INFO - iteration 219, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:34] {1180} INFO -  at 25.1s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:34] {1020} INFO - iteration 220, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:34] {1180} INFO -  at 25.3s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:34] {1020} INFO - iteration 221, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:34] {1180} INFO -  at 25.4s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:34] {1020} INFO - iteration 222, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:34] {1180} INFO -  at 25.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:34] {1020} INFO - iteration 223, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:34] {1180} INFO -  at 25.9s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:34] {1020} INFO - iteration 224, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:34] {1180} INFO -  at 26.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:34] {1020} INFO - iteration 225, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:35] {1180} INFO -  at 26.5s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:35] {1020} INFO - iteration 226, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:35] {1180} INFO -  at 26.6s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:35] {1020} INFO - iteration 227, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:35] {1180} INFO -  at 26.8s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:35] {1020} INFO - iteration 228, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:35] {1180} INFO -  at 27.0s,\tbest xgboost's error=0.0936,\tbest xgboost's error=0.0936\n",
            "[flaml.automl: 08-01 03:53:35] {1020} INFO - iteration 229, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:36] {1180} INFO -  at 27.2s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:36] {1020} INFO - iteration 230, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:36] {1180} INFO -  at 27.4s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:36] {1020} INFO - iteration 231, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:36] {1180} INFO -  at 27.7s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:36] {1020} INFO - iteration 232, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:36] {1180} INFO -  at 27.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:36] {1020} INFO - iteration 233, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:37] {1180} INFO -  at 28.1s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:37] {1020} INFO - iteration 234, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:37] {1180} INFO -  at 28.3s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:37] {1020} INFO - iteration 235, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:37] {1180} INFO -  at 28.5s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:37] {1020} INFO - iteration 236, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:37] {1180} INFO -  at 28.7s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:37] {1020} INFO - iteration 237, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:37] {1180} INFO -  at 28.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:37] {1020} INFO - iteration 238, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:38] {1180} INFO -  at 29.2s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:38] {1020} INFO - iteration 239, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:38] {1180} INFO -  at 29.4s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:38] {1020} INFO - iteration 240, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:38] {1180} INFO -  at 29.7s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:38] {1020} INFO - iteration 241, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:38] {1180} INFO -  at 29.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:38] {1020} INFO - iteration 242, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:39] {1180} INFO -  at 30.4s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:39] {1020} INFO - iteration 243, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:39] {1180} INFO -  at 30.7s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:39] {1020} INFO - iteration 244, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:39] {1180} INFO -  at 30.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:39] {1020} INFO - iteration 245, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:40] {1180} INFO -  at 31.3s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:40] {1020} INFO - iteration 246, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:40] {1180} INFO -  at 31.4s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:40] {1020} INFO - iteration 247, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:40] {1180} INFO -  at 31.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:40] {1020} INFO - iteration 248, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:40] {1180} INFO -  at 32.0s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:40] {1020} INFO - iteration 249, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:41] {1180} INFO -  at 32.2s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:41] {1020} INFO - iteration 250, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:41] {1180} INFO -  at 32.5s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:41] {1020} INFO - iteration 251, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:41] {1180} INFO -  at 32.8s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:41] {1020} INFO - iteration 252, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:41] {1180} INFO -  at 32.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:41] {1020} INFO - iteration 253, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:42] {1180} INFO -  at 33.1s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:42] {1020} INFO - iteration 254, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:42] {1180} INFO -  at 33.3s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:42] {1020} INFO - iteration 255, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:42] {1180} INFO -  at 33.7s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:42] {1020} INFO - iteration 256, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:42] {1180} INFO -  at 33.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:42] {1020} INFO - iteration 257, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:43] {1180} INFO -  at 34.1s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:43] {1020} INFO - iteration 258, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:43] {1180} INFO -  at 34.5s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:43] {1020} INFO - iteration 259, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:43] {1180} INFO -  at 34.7s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:43] {1020} INFO - iteration 260, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:43] {1180} INFO -  at 34.9s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:43] {1020} INFO - iteration 261, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:44] {1180} INFO -  at 35.1s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:44] {1020} INFO - iteration 262, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:44] {1180} INFO -  at 35.3s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:44] {1020} INFO - iteration 263, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:44] {1180} INFO -  at 35.5s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:44] {1020} INFO - iteration 264, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:44] {1180} INFO -  at 35.7s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:44] {1020} INFO - iteration 265, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:44] {1180} INFO -  at 35.8s,\tbest xgboost's error=0.0880,\tbest xgboost's error=0.0880\n",
            "[flaml.automl: 08-01 03:53:44] {1020} INFO - iteration 266, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:45] {1180} INFO -  at 36.5s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:45] {1020} INFO - iteration 267, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:45] {1180} INFO -  at 36.8s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:45] {1020} INFO - iteration 268, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:46] {1180} INFO -  at 37.6s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:46] {1020} INFO - iteration 269, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:47] {1180} INFO -  at 38.1s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:47] {1020} INFO - iteration 270, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:47] {1180} INFO -  at 38.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:47] {1020} INFO - iteration 271, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:48] {1180} INFO -  at 39.3s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:48] {1020} INFO - iteration 272, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:48] {1180} INFO -  at 40.0s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:48] {1020} INFO - iteration 273, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:49] {1180} INFO -  at 40.5s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:49] {1020} INFO - iteration 274, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:50] {1180} INFO -  at 41.1s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:50] {1020} INFO - iteration 275, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:50] {1180} INFO -  at 41.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:50] {1020} INFO - iteration 276, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:51] {1180} INFO -  at 42.3s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:51] {1020} INFO - iteration 277, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:51] {1180} INFO -  at 42.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:51] {1020} INFO - iteration 278, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:52] {1180} INFO -  at 43.5s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:52] {1020} INFO - iteration 279, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:52] {1180} INFO -  at 43.9s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:52] {1020} INFO - iteration 280, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:53] {1180} INFO -  at 44.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:53] {1020} INFO - iteration 281, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:54] {1180} INFO -  at 45.2s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:54] {1020} INFO - iteration 282, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:54] {1180} INFO -  at 45.9s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:54] {1020} INFO - iteration 283, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:55] {1180} INFO -  at 46.2s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:55] {1020} INFO - iteration 284, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:56] {1180} INFO -  at 47.0s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:56] {1020} INFO - iteration 285, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:56] {1180} INFO -  at 47.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:56] {1020} INFO - iteration 286, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:57] {1180} INFO -  at 48.2s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:57] {1020} INFO - iteration 287, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:57] {1180} INFO -  at 49.0s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:57] {1020} INFO - iteration 288, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:58] {1180} INFO -  at 49.2s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:58] {1020} INFO - iteration 289, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:58] {1180} INFO -  at 49.5s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:58] {1020} INFO - iteration 290, current learner xgboost\n",
            "[flaml.automl: 08-01 03:53:59] {1180} INFO -  at 50.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:53:59] {1020} INFO - iteration 291, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:00] {1180} INFO -  at 51.3s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:00] {1020} INFO - iteration 292, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:00] {1180} INFO -  at 51.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:00] {1020} INFO - iteration 293, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:01] {1180} INFO -  at 52.1s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:01] {1020} INFO - iteration 294, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:01] {1180} INFO -  at 53.0s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:01] {1020} INFO - iteration 295, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:02] {1180} INFO -  at 53.2s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:02] {1020} INFO - iteration 296, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:04] {1180} INFO -  at 55.1s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:04] {1020} INFO - iteration 297, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:04] {1180} INFO -  at 55.4s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:04] {1020} INFO - iteration 298, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:05] {1180} INFO -  at 56.5s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:05] {1020} INFO - iteration 299, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:05] {1180} INFO -  at 57.0s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:05] {1020} INFO - iteration 300, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:06] {1180} INFO -  at 57.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:06] {1020} INFO - iteration 301, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:06] {1180} INFO -  at 57.9s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:06] {1020} INFO - iteration 302, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:07] {1180} INFO -  at 59.0s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:07] {1020} INFO - iteration 303, current learner xgboost\n",
            "[flaml.automl: 08-01 03:54:08] {1180} INFO -  at 59.7s,\tbest xgboost's error=0.0863,\tbest xgboost's error=0.0863\n",
            "[flaml.automl: 08-01 03:54:08] {1220} INFO - selected model: <xgboost.core.Booster object at 0x7feded68c690>\n",
            "[flaml.automl: 08-01 03:54:08] {970} INFO - fit succeeded\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kagoznl2B4R",
        "outputId": "48ac57e9-67af-400c-8b14-e57bf2028e36"
      },
      "source": [
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best r2 on validation data: {0:.4g}'.format(1 - automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best hyperparmeter config: {'n_estimators': 204, 'max_leaves': 6, 'min_child_weight': 0.005632452124609419, 'learning_rate': 0.1325236559752437, 'subsample': 0.7584301068911125, 'colsample_bylevel': 0.738034831046731, 'colsample_bytree': 0.9369518394105365, 'reg_alpha': 0.011139933812249503, 'reg_lambda': 1.1373250806186728}\n",
            "Best r2 on validation data: 0.9137\n",
            "Training duration of best run: 0.7567 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oktocpcM2h53",
        "outputId": "947a2e72-01e5-49e3-afad-e365ace798ce"
      },
      "source": [
        "automl.model.estimator\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<xgboost.core.Booster at 0x7feded68c690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enc4FDR72uJE"
      },
      "source": [
        "import pickle\n",
        "with open('automl.pkl', 'wb') as f:\n",
        "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n0iLJle2yt1",
        "outputId": "b317899b-4381-4403-d9e5-7111af1eb865"
      },
      "source": [
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted labels [0.22710925 0.28422743 0.3984191  0.31287247 0.23266795 0.24291602\n",
            " 0.28147525 0.18855575 0.31287247 0.36037987 0.18193394 0.24287552\n",
            " 0.32612792 0.27838147 0.43183815 0.31574607 0.46550012 0.20076445\n",
            " 0.2285583  0.30401623 0.23184046 0.4551912  0.21121249 0.24269605\n",
            " 0.23040536 0.35311216 0.22878587 0.7481741  0.22290662 0.29414153\n",
            " 0.26774716 0.25841507 0.2563571  0.37733638 0.37467998 0.4467549\n",
            " 0.47245216 0.22705892 0.2162888  0.22800562 0.24970123 0.25428915\n",
            " 0.31592003 0.2479712  0.21594286 0.3385237  0.2154805  0.2137256\n",
            " 0.2545587  0.2171748  0.21149418 0.31706706 0.165862   0.21298099\n",
            " 0.31287247 0.2195046  0.20295775 0.1791066  0.23003286 0.42616683\n",
            " 0.37388816 0.3216949  0.38444698 0.21344069 0.32514727 0.7711323\n",
            " 0.2575004  0.29414153 0.44457155 0.91440797 0.5237487  0.22445396\n",
            " 0.23436147 0.8633385  0.21966901 0.3559221  0.23334473 0.2168827\n",
            " 0.4455067  0.19642061 0.24694574 0.2543124  0.37838423 0.26838958\n",
            " 0.40941414 0.21547377 0.24888694 0.280015   0.38917476 0.28855866\n",
            " 0.2488653  0.21802273 0.47379455 0.31132042 0.20867336 0.25731748\n",
            " 0.77480346]\n",
            "True labels [0.21917643 0.27818809 0.40511291 0.31265151 0.23778331 0.24800347\n",
            " 0.28369611 0.17856737 0.31265151 0.36357127 0.18381411 0.25063885\n",
            " 0.33606539 0.27245635 0.42178722 0.29133539 0.45020199 0.19901267\n",
            " 0.22447942 0.29905025 0.22852274 0.4329961  0.2141382  0.23889379\n",
            " 0.22826206 0.36601494 0.23549833 0.86533941 0.22725153 0.2975256\n",
            " 0.25335627 0.2477512  0.25477349 0.37855777 0.36944037 0.38128842\n",
            " 0.50820582 0.22283376 0.21248944 0.23009967 0.25296851 0.26441304\n",
            " 0.31115992 0.24183576 0.21065268 0.3526167  0.21639962 0.21771809\n",
            " 0.26214353 0.21406141 0.21773848 0.35319151 0.16583135 0.20825377\n",
            " 0.31265151 0.21516789 0.2023169  0.17749364 0.23798032 0.42255063\n",
            " 0.40171385 0.33224359 0.39445262 0.21352858 0.29783829 0.76730889\n",
            " 0.25679179 0.2975256  0.46018895 1.01539504 0.50211921 0.22201358\n",
            " 0.23952114 0.89107969 0.22153071 0.33307531 0.22514142 0.20765063\n",
            " 0.39979483 0.20029738 0.2522879  0.253804   0.42367496 0.26945119\n",
            " 0.4068906  0.21928185 0.25053893 0.28409183 0.38074108 0.29180421\n",
            " 0.25100178 0.21992977 0.48665542 0.30862698 0.20850588 0.25532952\n",
            " 0.94368132]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c5mBpff26yP",
        "outputId": "87628c5d-6996-4745-dec7-ae2744e65d45"
      },
      "source": [
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
        "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 = 0.970573989284961\n",
            "mse = 0.0007324448420536676\n",
            "mae = 0.012334653570777112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVrtwX0c3CnO",
        "outputId": "e7aed7c7-ac51-40c8-b596-8e54f461d9d5"
      },
      "source": [
        "\n",
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, train_loss_history = \\\n",
        "    get_output_from_log(filename=settings['log_file_name'], time_budget=60)\n",
        "\n",
        "for config in config_history:\n",
        "    print(config)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.2620811530815948, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.2620811530815948, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791107017, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791107017, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.587361044106064, 'learning_rate': 0.5305016568114994, 'subsample': 0.8132820472645403, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8110207792444197, 'reg_alpha': 0.002464557255174736, 'reg_lambda': 0.6369900700728743}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.587361044106064, 'learning_rate': 0.5305016568114994, 'subsample': 0.8132820472645403, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8110207792444197, 'reg_alpha': 0.002464557255174736, 'reg_lambda': 0.6369900700728743}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 6, 'max_leaves': 4, 'min_child_weight': 1.1963412491515157, 'learning_rate': 1.0, 'subsample': 0.9053173419759986, 'colsample_bylevel': 0.6995337995779759, 'colsample_bytree': 0.6609235517940241, 'reg_alpha': 0.004000561469103885, 'reg_lambda': 2.846084429086738}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 6, 'max_leaves': 4, 'min_child_weight': 1.1963412491515157, 'learning_rate': 1.0, 'subsample': 0.9053173419759986, 'colsample_bylevel': 0.6995337995779759, 'colsample_bytree': 0.6609235517940241, 'reg_alpha': 0.004000561469103885, 'reg_lambda': 2.846084429086738}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 12, 'max_leaves': 4, 'min_child_weight': 1.093179875425754, 'learning_rate': 0.5856946902963877, 'subsample': 1.0, 'colsample_bylevel': 0.852941886797637, 'colsample_bytree': 0.6668185206475564, 'reg_alpha': 0.007111777773771672, 'reg_lambda': 0.697468197415849}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 12, 'max_leaves': 4, 'min_child_weight': 1.093179875425754, 'learning_rate': 0.5856946902963877, 'subsample': 1.0, 'colsample_bylevel': 0.852941886797637, 'colsample_bytree': 0.6668185206475564, 'reg_alpha': 0.007111777773771672, 'reg_lambda': 0.697468197415849}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 13, 'max_leaves': 6, 'min_child_weight': 0.8796274094305008, 'learning_rate': 0.5802438517578076, 'subsample': 0.8414658415609443, 'colsample_bylevel': 0.8912912548196453, 'colsample_bytree': 0.7288039223637289, 'reg_alpha': 0.004099203256159086, 'reg_lambda': 12.339443327073033}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 13, 'max_leaves': 6, 'min_child_weight': 0.8796274094305008, 'learning_rate': 0.5802438517578076, 'subsample': 0.8414658415609443, 'colsample_bylevel': 0.8912912548196453, 'colsample_bytree': 0.7288039223637289, 'reg_alpha': 0.004099203256159086, 'reg_lambda': 12.339443327073033}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 35, 'max_leaves': 4, 'min_child_weight': 0.17581359667292432, 'learning_rate': 0.44642881097763815, 'subsample': 0.9432870475231855, 'colsample_bylevel': 0.8642927616807163, 'colsample_bytree': 0.7170983975721215, 'reg_alpha': 0.00370895986460914, 'reg_lambda': 15.22254508992119}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 35, 'max_leaves': 4, 'min_child_weight': 0.17581359667292432, 'learning_rate': 0.44642881097763815, 'subsample': 0.9432870475231855, 'colsample_bylevel': 0.8642927616807163, 'colsample_bytree': 0.7170983975721215, 'reg_alpha': 0.00370895986460914, 'reg_lambda': 15.22254508992119}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 78, 'max_leaves': 4, 'min_child_weight': 0.025790038066620766, 'learning_rate': 0.4657498463113674, 'subsample': 0.8479487966809013, 'colsample_bylevel': 0.8952343204215536, 'colsample_bytree': 0.769875196832885, 'reg_alpha': 0.004725499215101061, 'reg_lambda': 4.933635833874812}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 78, 'max_leaves': 4, 'min_child_weight': 0.025790038066620766, 'learning_rate': 0.4657498463113674, 'subsample': 0.8479487966809013, 'colsample_bylevel': 0.8952343204215536, 'colsample_bytree': 0.769875196832885, 'reg_alpha': 0.004725499215101061, 'reg_lambda': 4.933635833874812}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 67, 'max_leaves': 6, 'min_child_weight': 0.013321490439734043, 'learning_rate': 0.21989011707643502, 'subsample': 0.6755628271616013, 'colsample_bylevel': 0.7778464439667864, 'colsample_bytree': 0.7707184508307768, 'reg_alpha': 0.0019600896362308167, 'reg_lambda': 17.23707002972416}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 67, 'max_leaves': 6, 'min_child_weight': 0.013321490439734043, 'learning_rate': 0.21989011707643502, 'subsample': 0.6755628271616013, 'colsample_bylevel': 0.7778464439667864, 'colsample_bytree': 0.7707184508307768, 'reg_alpha': 0.0019600896362308167, 'reg_lambda': 17.23707002972416}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 67, 'max_leaves': 7, 'min_child_weight': 0.005955358784699612, 'learning_rate': 0.2316660975742496, 'subsample': 0.4689801177546289, 'colsample_bylevel': 0.726350334476035, 'colsample_bytree': 0.8267493331778778, 'reg_alpha': 0.0009765625, 'reg_lambda': 6.603038921421143}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 67, 'max_leaves': 7, 'min_child_weight': 0.005955358784699612, 'learning_rate': 0.2316660975742496, 'subsample': 0.4689801177546289, 'colsample_bylevel': 0.726350334476035, 'colsample_bytree': 0.8267493331778778, 'reg_alpha': 0.0009765625, 'reg_lambda': 6.603038921421143}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 43, 'max_leaves': 7, 'min_child_weight': 0.01900525107376159, 'learning_rate': 0.14705505516567102, 'subsample': 0.6382865781581051, 'colsample_bylevel': 0.651997298030279, 'colsample_bytree': 0.8972531544046104, 'reg_alpha': 0.0016990230161749236, 'reg_lambda': 0.9675632409638225}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 43, 'max_leaves': 7, 'min_child_weight': 0.01900525107376159, 'learning_rate': 0.14705505516567102, 'subsample': 0.6382865781581051, 'colsample_bylevel': 0.651997298030279, 'colsample_bytree': 0.8972531544046104, 'reg_alpha': 0.0016990230161749236, 'reg_lambda': 0.9675632409638225}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 49, 'max_leaves': 6, 'min_child_weight': 0.023918582634664846, 'learning_rate': 0.16977701055332545, 'subsample': 0.5001098003952943, 'colsample_bylevel': 0.7784721181420432, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.877899290124467}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 49, 'max_leaves': 6, 'min_child_weight': 0.023918582634664846, 'learning_rate': 0.16977701055332545, 'subsample': 0.5001098003952943, 'colsample_bylevel': 0.7784721181420432, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.877899290124467}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 72, 'max_leaves': 5, 'min_child_weight': 0.023345479177605696, 'learning_rate': 0.19773981511918864, 'subsample': 0.6739018528889392, 'colsample_bylevel': 0.7101170246395152, 'colsample_bytree': 1.0, 'reg_alpha': 0.006312313443616572, 'reg_lambda': 2.7356666217585057}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 72, 'max_leaves': 5, 'min_child_weight': 0.023345479177605696, 'learning_rate': 0.19773981511918864, 'subsample': 0.6739018528889392, 'colsample_bylevel': 0.7101170246395152, 'colsample_bytree': 1.0, 'reg_alpha': 0.006312313443616572, 'reg_lambda': 2.7356666217585057}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 388, 'Current Hyper-parameters': {'n_estimators': 204, 'max_leaves': 6, 'min_child_weight': 0.005632452124609419, 'learning_rate': 0.1325236559752437, 'subsample': 0.7584301068911125, 'colsample_bylevel': 0.738034831046731, 'colsample_bytree': 0.9369518394105365, 'reg_alpha': 0.011139933812249503, 'reg_lambda': 1.1373250806186728}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 204, 'max_leaves': 6, 'min_child_weight': 0.005632452124609419, 'learning_rate': 0.1325236559752437, 'subsample': 0.7584301068911125, 'colsample_bylevel': 0.738034831046731, 'colsample_bytree': 0.9369518394105365, 'reg_alpha': 0.011139933812249503, 'reg_lambda': 1.1373250806186728}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "s6HDunlc3FWe",
        "outputId": "34303634-b637-4f88-b8b0-e7f278ff5359"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation r2')\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zluPonwY3I4j",
        "outputId": "def1150b-df8d-47e3-afc6-696981543d56"
      },
      "source": [
        "print('flaml (60s) r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flaml (60s) r2 = 0.970573989284961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heDik4Vm3M7W"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "xgb = XGBRegressor()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx1YS_oV3Pqh",
        "outputId": "6e1d02a8-c6c9-443b-df92-42d763c6a617"
      },
      "source": [
        "xgb.fit(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[03:58:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOtmts5C3S8B",
        "outputId": "4162fae9-ed40-4c3c-852b-77b0e8009917"
      },
      "source": [
        "y_pred = xgb.predict(X_test)\n",
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('default xgboost r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default xgboost r2 = 0.9534410088970411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euyiw18o3WVe",
        "outputId": "295d670f-cd52-4e75-e84f-8e4013494fd4"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "''' define your customized objective function '''\n",
        "def logregobj(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    preds = 1.0 / (1.0 + np.exp(-preds)) # transform raw leaf weight\n",
        "    grad = preds - labels\n",
        "    hess = preds * (1.0 - preds)\n",
        "    return grad, hess\n",
        "\n",
        "''' create customized XGBoost learners class with your objective function '''\n",
        "from flaml.model import XGBoostEstimator\n",
        "\n",
        "\n",
        "class MyXGB1(XGBoostEstimator):\n",
        "    '''XGBoostEstimator with the logregobj function as the objective function\n",
        "    '''\n",
        "\n",
        "    def __init__(self, **params):\n",
        "        super().__init__(objective=logregobj, **params) \n",
        "\n",
        "\n",
        "class MyXGB2(XGBoostEstimator):\n",
        "    '''XGBoostEstimator with 'reg:squarederror' as the objective function\n",
        "    '''\n",
        "\n",
        "    def __init__(self, **params):\n",
        "        super().__init__(objective='reg:gamma', **params)\n",
        "\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.add_learner(learner_name='my_xgb1', learner_class=MyXGB1)\n",
        "automl.add_learner(learner_name='my_xgb2', learner_class=MyXGB2)\n",
        "settings = {\n",
        "    \"time_budget\": 30,  # total running time in seconds\n",
        "    \"metric\": 'r2',  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
        "    \"estimator_list\": ['my_xgb1', 'my_xgb2'],  # list of ML learners; we tune lightgbm in this example\n",
        "    \"task\": 'regression',  # task type    \n",
        "    \n",
        "}\n",
        "automl.fit(X_train=X_train, y_train=y_train, **settings)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[flaml.automl: 08-01 04:00:20] {913} INFO - Evaluation method: cv\n",
            "[flaml.automl: 08-01 04:00:20] {617} INFO - Using RepeatedKFold\n",
            "[flaml.automl: 08-01 04:00:20] {934} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 08-01 04:00:20] {954} INFO - List of ML learners in AutoML Run: ['my_xgb1', 'my_xgb2']\n",
            "[flaml.automl: 08-01 04:00:20] {1020} INFO - iteration 0, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:20] {1180} INFO -  at 0.1s,\tbest my_xgb1's error=5.6422,\tbest my_xgb1's error=5.6422\n",
            "[flaml.automl: 08-01 04:00:20] {1020} INFO - iteration 1, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:20] {1180} INFO -  at 0.1s,\tbest my_xgb1's error=0.5948,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:20] {1020} INFO - iteration 2, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:20] {1180} INFO -  at 0.1s,\tbest my_xgb1's error=0.5948,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:20] {1020} INFO - iteration 3, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:20] {1180} INFO -  at 0.2s,\tbest my_xgb1's error=0.5948,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 4, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.2s,\tbest my_xgb2's error=1.3259,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 5, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.2s,\tbest my_xgb1's error=0.5948,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 6, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.3s,\tbest my_xgb1's error=0.5948,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 7, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.3s,\tbest my_xgb1's error=0.5948,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 8, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.3s,\tbest my_xgb2's error=1.3259,\tbest my_xgb1's error=0.5948\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 9, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.4s,\tbest my_xgb2's error=0.3708,\tbest my_xgb2's error=0.3708\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 10, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.4s,\tbest my_xgb2's error=0.3708,\tbest my_xgb2's error=0.3708\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 11, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.5s,\tbest my_xgb2's error=0.3708,\tbest my_xgb2's error=0.3708\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 12, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.5s,\tbest my_xgb2's error=0.3708,\tbest my_xgb2's error=0.3708\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 13, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.6s,\tbest my_xgb2's error=0.2380,\tbest my_xgb2's error=0.2380\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 14, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.6s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.2380\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 15, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.6s,\tbest my_xgb2's error=0.2380,\tbest my_xgb2's error=0.2380\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 16, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.7s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.2380\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 17, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.7s,\tbest my_xgb2's error=0.2380,\tbest my_xgb2's error=0.2380\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 18, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.7s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.2380\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 19, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.8s,\tbest my_xgb2's error=0.1765,\tbest my_xgb2's error=0.1765\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 20, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.8s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1765\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 21, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.9s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1765\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 22, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 0.9s,\tbest my_xgb2's error=0.1765,\tbest my_xgb2's error=0.1765\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 23, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 1.0s,\tbest my_xgb2's error=0.1765,\tbest my_xgb2's error=0.1765\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 24, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 1.0s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1765\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 25, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 1.1s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 26, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:21] {1180} INFO -  at 1.1s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:21] {1020} INFO - iteration 27, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.2s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 28, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.2s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 29, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.3s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 30, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.3s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 31, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.3s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 32, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.4s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 33, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.5s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 34, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.5s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 35, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.6s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 36, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.7s,\tbest my_xgb2's error=0.1330,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 37, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.7s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1330\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 38, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 1.9s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 39, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 2.0s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 40, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 2.0s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 41, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:22] {1180} INFO -  at 2.1s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:22] {1020} INFO - iteration 42, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.2s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 43, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.3s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 44, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.4s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 45, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.4s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 46, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.5s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 47, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.5s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 48, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.7s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 49, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.7s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 50, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.7s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 51, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.8s,\tbest my_xgb1's error=0.5948,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 52, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.8s,\tbest my_xgb1's error=0.5627,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 53, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 2.9s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 54, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 3.0s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 55, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:23] {1180} INFO -  at 3.1s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:23] {1020} INFO - iteration 56, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 3.4s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 57, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 3.4s,\tbest my_xgb1's error=0.5627,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 58, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 3.5s,\tbest my_xgb2's error=0.1171,\tbest my_xgb2's error=0.1171\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 59, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 3.6s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 60, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 3.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 61, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 3.8s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 62, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 4.0s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 63, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:24] {1180} INFO -  at 4.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:24] {1020} INFO - iteration 64, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.2s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 65, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.3s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 66, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.4s,\tbest my_xgb1's error=0.5627,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 67, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 68, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 69, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.6s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 70, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.8s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 71, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 72, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 4.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 73, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 5.0s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 74, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:25] {1180} INFO -  at 5.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:25] {1020} INFO - iteration 75, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.2s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 76, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.3s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 77, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.4s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 78, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 79, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 80, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 81, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.8s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 82, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 5.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 83, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 6.0s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 84, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:26] {1180} INFO -  at 6.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:26] {1020} INFO - iteration 85, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 6.3s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 86, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 6.4s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 87, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 6.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 88, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 6.6s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 89, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 6.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 90, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 6.8s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 91, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 6.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 92, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 7.0s,\tbest my_xgb1's error=0.5627,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 93, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 7.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 94, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:27] {1180} INFO -  at 7.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:27] {1020} INFO - iteration 95, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 7.3s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 96, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 7.4s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 97, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 7.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 98, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 7.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 99, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 7.8s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 100, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 7.8s,\tbest my_xgb1's error=0.5627,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 101, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 7.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 102, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 8.0s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 103, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 8.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 104, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:28] {1180} INFO -  at 8.2s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:28] {1020} INFO - iteration 105, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.2s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 106, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.4s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 107, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 108, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.6s,\tbest my_xgb1's error=0.5627,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 109, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.6s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 110, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 111, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.8s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 112, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 8.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 113, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 9.0s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 114, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 9.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 115, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:29] {1180} INFO -  at 9.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:29] {1020} INFO - iteration 116, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.2s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 117, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.3s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 118, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.4s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 119, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 120, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 121, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.7s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 122, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.7s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 123, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.8s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 124, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.8s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 125, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 9.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 126, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 10.0s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 127, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:30] {1180} INFO -  at 10.1s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:30] {1020} INFO - iteration 128, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.2s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 129, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.3s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 130, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.4s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 131, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.5s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 132, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.6s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 133, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.7s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 134, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.8s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 135, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.8s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 136, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 10.9s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 137, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 11.0s,\tbest my_xgb2's error=0.1136,\tbest my_xgb2's error=0.1136\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 138, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:31] {1180} INFO -  at 11.2s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:31] {1020} INFO - iteration 139, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.3s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 140, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.5s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 141, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.6s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 142, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.7s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 143, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.7s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 144, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.8s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 145, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.8s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 146, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.8s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 147, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 11.9s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 148, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 12.0s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 149, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:32] {1180} INFO -  at 12.1s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:32] {1020} INFO - iteration 150, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 12.2s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 151, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 12.2s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 152, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 12.3s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 153, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 12.4s,\tbest my_xgb2's error=0.1089,\tbest my_xgb2's error=0.1089\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 154, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 12.6s,\tbest my_xgb2's error=0.1013,\tbest my_xgb2's error=0.1013\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 155, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 12.8s,\tbest my_xgb2's error=0.1013,\tbest my_xgb2's error=0.1013\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 156, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 13.0s,\tbest my_xgb2's error=0.1013,\tbest my_xgb2's error=0.1013\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 157, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:33] {1180} INFO -  at 13.1s,\tbest my_xgb2's error=0.1013,\tbest my_xgb2's error=0.1013\n",
            "[flaml.automl: 08-01 04:00:33] {1020} INFO - iteration 158, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:34] {1180} INFO -  at 13.4s,\tbest my_xgb2's error=0.1013,\tbest my_xgb2's error=0.1013\n",
            "[flaml.automl: 08-01 04:00:34] {1020} INFO - iteration 159, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:34] {1180} INFO -  at 13.8s,\tbest my_xgb2's error=0.0974,\tbest my_xgb2's error=0.0974\n",
            "[flaml.automl: 08-01 04:00:34] {1020} INFO - iteration 160, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:34] {1180} INFO -  at 14.0s,\tbest my_xgb2's error=0.0974,\tbest my_xgb2's error=0.0974\n",
            "[flaml.automl: 08-01 04:00:34] {1020} INFO - iteration 161, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:35] {1180} INFO -  at 14.8s,\tbest my_xgb2's error=0.0974,\tbest my_xgb2's error=0.0974\n",
            "[flaml.automl: 08-01 04:00:35] {1020} INFO - iteration 162, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:36] {1180} INFO -  at 15.2s,\tbest my_xgb2's error=0.0974,\tbest my_xgb2's error=0.0974\n",
            "[flaml.automl: 08-01 04:00:36] {1020} INFO - iteration 163, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:36] {1180} INFO -  at 15.5s,\tbest my_xgb2's error=0.0974,\tbest my_xgb2's error=0.0974\n",
            "[flaml.automl: 08-01 04:00:36] {1020} INFO - iteration 164, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:36] {1180} INFO -  at 15.7s,\tbest my_xgb2's error=0.0974,\tbest my_xgb2's error=0.0974\n",
            "[flaml.automl: 08-01 04:00:36] {1020} INFO - iteration 165, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:37] {1180} INFO -  at 16.5s,\tbest my_xgb2's error=0.0936,\tbest my_xgb2's error=0.0936\n",
            "[flaml.automl: 08-01 04:00:37] {1020} INFO - iteration 166, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:37] {1180} INFO -  at 17.1s,\tbest my_xgb2's error=0.0936,\tbest my_xgb2's error=0.0936\n",
            "[flaml.automl: 08-01 04:00:37] {1020} INFO - iteration 167, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:37] {1180} INFO -  at 17.1s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0936\n",
            "[flaml.automl: 08-01 04:00:37] {1020} INFO - iteration 168, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:38] {1180} INFO -  at 17.9s,\tbest my_xgb2's error=0.0936,\tbest my_xgb2's error=0.0936\n",
            "[flaml.automl: 08-01 04:00:38] {1020} INFO - iteration 169, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:39] {1180} INFO -  at 18.7s,\tbest my_xgb2's error=0.0892,\tbest my_xgb2's error=0.0892\n",
            "[flaml.automl: 08-01 04:00:39] {1020} INFO - iteration 170, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:39] {1180} INFO -  at 19.0s,\tbest my_xgb2's error=0.0892,\tbest my_xgb2's error=0.0892\n",
            "[flaml.automl: 08-01 04:00:39] {1020} INFO - iteration 171, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:41] {1180} INFO -  at 20.8s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:41] {1020} INFO - iteration 172, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:42] {1180} INFO -  at 21.5s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:42] {1020} INFO - iteration 173, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:44] {1180} INFO -  at 23.5s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:44] {1020} INFO - iteration 174, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:44] {1180} INFO -  at 24.0s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:44] {1020} INFO - iteration 175, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:46] {1180} INFO -  at 25.4s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:46] {1020} INFO - iteration 176, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:47] {1180} INFO -  at 27.0s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:47] {1020} INFO - iteration 177, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:48] {1180} INFO -  at 28.2s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:48] {1020} INFO - iteration 178, current learner my_xgb2\n",
            "[flaml.automl: 08-01 04:00:49] {1180} INFO -  at 29.1s,\tbest my_xgb2's error=0.0876,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:49] {1020} INFO - iteration 179, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:49] {1180} INFO -  at 29.2s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:49] {1020} INFO - iteration 180, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.2s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 181, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.2s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 182, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.3s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 183, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.3s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 184, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.3s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 185, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.4s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 186, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.4s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 187, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.4s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 188, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.5s,\tbest my_xgb1's error=0.5513,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 189, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.5s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 190, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.6s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 191, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.6s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 192, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.7s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 193, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.7s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 194, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.8s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 195, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.8s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 196, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.9s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 197, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 29.9s,\tbest my_xgb1's error=0.4610,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1020} INFO - iteration 198, current learner my_xgb1\n",
            "[flaml.automl: 08-01 04:00:50] {1180} INFO -  at 30.0s,\tbest my_xgb1's error=0.4045,\tbest my_xgb2's error=0.0876\n",
            "[flaml.automl: 08-01 04:00:50] {1220} INFO - selected model: <xgboost.core.Booster object at 0x7feded6939d0>\n",
            "[flaml.automl: 08-01 04:00:50] {970} INFO - fit succeeded\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lei52-cS3dEt",
        "outputId": "fbbc7f2b-1d81-4ecb-d344-223aeb124ee3"
      },
      "source": [
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best r2 on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
        "\n",
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)\n",
        "\n",
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
        "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best hyperparmeter config: {'n_estimators': 388, 'max_leaves': 6, 'min_child_weight': 0.1536939383068592, 'learning_rate': 0.07325108998320864, 'subsample': 0.7364103002327189, 'colsample_bylevel': 0.9353049063592492, 'colsample_bytree': 1.0, 'reg_alpha': 0.008071628159455732, 'reg_lambda': 2.676707245908972}\n",
            "Best r2 on validation data: 0.9124\n",
            "Training duration of best run: 1.821 s\n",
            "Predicted labels [0.22985798 0.2823881  0.38726646 0.3180356  0.23282781 0.2484642\n",
            " 0.28358695 0.19276106 0.3180356  0.356709   0.18307744 0.24455424\n",
            " 0.3270215  0.2718567  0.43626663 0.32338855 0.43455425 0.19614036\n",
            " 0.22431697 0.30082977 0.23566099 0.4233394  0.21388377 0.24636512\n",
            " 0.2308634  0.3610587  0.23127334 0.8789088  0.22848304 0.29312855\n",
            " 0.26495647 0.24302562 0.25606298 0.37022203 0.37206066 0.4224815\n",
            " 0.48477155 0.22710903 0.21344194 0.22427237 0.25334623 0.26071486\n",
            " 0.31469193 0.23833399 0.21432146 0.3435551  0.2159092  0.21770355\n",
            " 0.2558709  0.21592212 0.20686288 0.335696   0.16903044 0.21077251\n",
            " 0.3180356  0.21489966 0.20207231 0.17620367 0.22829492 0.42738202\n",
            " 0.398009   0.32892203 0.3743077  0.21138704 0.3202209  0.790817\n",
            " 0.25047097 0.29312855 0.4345071  0.93179107 0.48992977 0.21966195\n",
            " 0.23572473 0.98231107 0.2181818  0.3255477  0.22707449 0.21767794\n",
            " 0.42975652 0.20046607 0.23955448 0.2436899  0.4097643  0.27256203\n",
            " 0.4080587  0.21848966 0.24594279 0.28807122 0.37184194 0.2920183\n",
            " 0.24984448 0.22037296 0.4967265  0.3110067  0.20700239 0.26118323\n",
            " 0.91475147]\n",
            "True labels [0.21917643 0.27818809 0.40511291 0.31265151 0.23778331 0.24800347\n",
            " 0.28369611 0.17856737 0.31265151 0.36357127 0.18381411 0.25063885\n",
            " 0.33606539 0.27245635 0.42178722 0.29133539 0.45020199 0.19901267\n",
            " 0.22447942 0.29905025 0.22852274 0.4329961  0.2141382  0.23889379\n",
            " 0.22826206 0.36601494 0.23549833 0.86533941 0.22725153 0.2975256\n",
            " 0.25335627 0.2477512  0.25477349 0.37855777 0.36944037 0.38128842\n",
            " 0.50820582 0.22283376 0.21248944 0.23009967 0.25296851 0.26441304\n",
            " 0.31115992 0.24183576 0.21065268 0.3526167  0.21639962 0.21771809\n",
            " 0.26214353 0.21406141 0.21773848 0.35319151 0.16583135 0.20825377\n",
            " 0.31265151 0.21516789 0.2023169  0.17749364 0.23798032 0.42255063\n",
            " 0.40171385 0.33224359 0.39445262 0.21352858 0.29783829 0.76730889\n",
            " 0.25679179 0.2975256  0.46018895 1.01539504 0.50211921 0.22201358\n",
            " 0.23952114 0.89107969 0.22153071 0.33307531 0.22514142 0.20765063\n",
            " 0.39979483 0.20029738 0.2522879  0.253804   0.42367496 0.26945119\n",
            " 0.4068906  0.21928185 0.25053893 0.28409183 0.38074108 0.29180421\n",
            " 0.25100178 0.21992977 0.48665542 0.30862698 0.20850588 0.25532952\n",
            " 0.94368132]\n",
            "r2 = 0.9890343884099644\n",
            "mse = 0.0002729457868708205\n",
            "mae = 0.008960440259333471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8R1Rwqi30GR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}